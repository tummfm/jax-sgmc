{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from jax import nn, tree_leaves, random, numpy as jnp\n",
    "from jax_sgmc import data, potential, adaption, scheduler, integrator, solver, io\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets\n",
    "import haiku as hk\n",
    "\n",
    "import sys\n",
    "\n",
    "from jax import config\n",
    "# config.update('TF_CPP_MIN_LOG_LEVEL', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Configuration parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "cached_batches = 1024\n",
    "num_classes = 100\n",
    "weight_decay = 5.e-4\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
      "/usr/local/Caskroom/miniconda/base/envs/SGMC/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py:3085: UserWarning: Explicitly requested dtype int64 requested in zeros is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  lax._check_user_dtype_supported(dtype, \"zeros\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'X': ShapeDtypeStruct(shape=(32, 32, 32, 3), dtype=uint8)}\n",
      "{'X': ShapeDtypeStruct(shape=(32, 32, 32, 3), dtype=uint8), 'Y': ShapeDtypeStruct(shape=(32, 1), dtype=int64)}\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = \\\n",
    "    tf.keras.datasets.cifar100.load_data(label_mode='fine')\n",
    "\n",
    "# Use tensorflow dataset directly. The 'id' must be excluded as text is not\n",
    "# supported by jax\n",
    "train_dataset, train_info = tensorflow_datasets.load('Cifar100',\n",
    "                                                     split='train',\n",
    "                                                     with_info=True)\n",
    "train_loader = data.TensorflowDataLoader(train_dataset,\n",
    "                                         batch_size,\n",
    "                                         shuffle_cache=1000,\n",
    "                                         exclude_keys=['id'])\n",
    "\n",
    "test_loader = data.NumpyDataLoader(batch_size, X=test_images, Y=test_labels)\n",
    "\n",
    "train_batch_fn = data.random_reference_data(train_loader, cached_batches)\n",
    "\n",
    "# get first batch to init NN\n",
    "# TODO: Maybe write convenience function for this common usecase?\n",
    "batch_init, batch_get = train_batch_fn\n",
    "# This method returns a batch with correct shape but all zero values. The batch\n",
    "# contains 32 (batch_size) images.\n",
    "init_batch = train_loader.initializer_batch()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ResNet Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "def init_resnet():\n",
    "    @hk.transform_with_state\n",
    "    def resnet(batch, is_training=True):\n",
    "        images = batch[\"image\"].astype(jnp.float32) / 255.\n",
    "        resnet50 = hk.nets.ResNet50(num_classes)\n",
    "        logits = resnet50(images, is_training=is_training)\n",
    "        return logits\n",
    "    return resnet.init, resnet.apply\n",
    "\n",
    "init, apply_resnet = init_resnet()\n",
    "init_params, init_resnet_state = init(random.PRNGKey(0), init_batch)\n",
    "\n",
    "# test prediction\n",
    "logits, _ = apply_resnet(init_params, init_resnet_state, None, init_batch)\n",
    "\n",
    "print(jnp.sum(logits))\n",
    "# I don't think this should give plain 0, otherwise gradients will be 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialize potential\n",
    "\n",
    "Everything below is still implemented without the state!\n",
    "Can we somehow provide additional arguments to likelihood?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def likelihood(resnet_state, sample, observations):\n",
    "    labels = nn.one_hot(observations[\"label\"], num_classes)\n",
    "    logits, resnet_state = apply_resnet(sample[\"w\"], resnet_state, None, observations)\n",
    "    softmax_xent = -jnp.sum(labels * nn.log_softmax(logits))\n",
    "    softmax_xent /= labels.shape[0]\n",
    "    return softmax_xent, resnet_state\n",
    "\n",
    "def prior(sample):\n",
    "    # Implement weight decay, corresponds to Gaussian prior over weights\n",
    "    weights = sample[\"w\"]\n",
    "    l2_loss = 0.5 * sum(jnp.sum(jnp.square(p)) for p in tree_leaves(weights))\n",
    "    return weight_decay * l2_loss\n",
    "\n",
    "# The likelihood accepts a batch of data, so not batching strategy is required,\n",
    "# instead, is_batched must be set to true.\n",
    "#\n",
    "# The likelihood signature changes from\n",
    "#   (Sample, Data) -> Likelihood\n",
    "# to\n",
    "#   (State, Sample, Data) -> Likelihood, NewState\n",
    "# if has_state is set to true.\n",
    "potential_fn = potential.minibatch_potential(prior=prior,\n",
    "                                             likelihood=likelihood,\n",
    "                                             has_state=True,\n",
    "                                             is_batched=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup Integrator\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Number of iterations: Ca. 0.035 seconds per iteration (including saving)\n",
    "iterations = 100000\n",
    "\n",
    "# Adaption strategy\n",
    "rms_prop = adaption.rms_prop()\n",
    "\n",
    "# Integrators\n",
    "rms_integrator = integrator.langevin_diffusion(potential_fn,\n",
    "                                               train_batch_fn,\n",
    "                                               rms_prop)\n",
    "\n",
    "# Initial value for starting\n",
    "sample = {\"w\": init_params}\n",
    "\n",
    "# Schedulers\n",
    "rms_step_size = scheduler.polynomial_step_size_first_last(first=0.05,\n",
    "                                                          last=0.001)\n",
    "burn_in = scheduler.initial_burn_in(50000)\n",
    "# Has ca. 23.000.000 parameters, so not more than 500 samples fit into RAM\n",
    "rms_random_thinning = scheduler.random_thinning(rms_step_size, burn_in, 500)\n",
    "\n",
    "rms_scheduler = scheduler.init_scheduler(step_size=rms_step_size,\n",
    "                                         burn_in=burn_in,\n",
    "                                         thinning=rms_random_thinning)\n",
    "\n",
    "# This is the most efficient option, in which case the selected samples are\n",
    "# stored and returned as trees of numpy arrays\n",
    "data_collector = io.MemoryCollector()\n",
    "saving = io.save(data_collector)\n",
    "\n",
    "rms_sgld = solver.sgmc(rms_integrator)\n",
    "rms_run = solver.mcmc(rms_sgld,\n",
    "                      rms_scheduler,\n",
    "                      saving=saving)\n",
    "\n",
    "# The initial state for the likelihood must be passed as a keyword argument just\n",
    "# like the initial sample.\n",
    "rms = rms_run(rms_integrator[0](sample, init_model_state=init_resnet_state),\n",
    "              iterations=iterations)[\"samples\"][\"variables\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Todo: Evaluation of training\n",
    "# Pickling is not possible (3-4G limit)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}