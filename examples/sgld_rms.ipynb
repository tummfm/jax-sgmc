{
 "cells": [
  {
   "cell_type": "raw",
   "id": "1ffc791c",
   "metadata": {},
   "source": [
    "---\n",
    "Copyright 2021 Multiscale Modeling of Fluid Materials, TU Munich\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "  http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdc4f7d",
   "metadata": {
    "collapsed": false,
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as onp\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "from jax.scipy.stats import norm\n",
    "\n",
    "from jax_sgmc import data, potential, scheduler, adaption, integrator, solver, io\n",
    "from jax_sgmc.data.numpy_loader import NumpyDataLoader\n",
    "from jax_sgmc.data.hdf5_loader import HDF5Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b118a0ec",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Setup Custom Solver\n",
    "\n",
    "This example shows how to customize a solver by combining the individual\n",
    "modules of **JaxSGMC**.\n",
    "It covers all necessary steps to build a *SGLD* solver with *RMSprop* adaption\n",
    "and applies it to the same problem as described in {doc}`/quickstart/`.\n",
    "\n",
    "## Overview\n",
    "\n",
    "Schematically, a solver in **JaxSGMC** has the structure:\n",
    "\n",
    "![Structure of JaxSGMC](../jax-sgmc-structure.svg)\n",
    "\n",
    "The SGLD solver with RMSprop adaption will make use of all modules.\n",
    "It is set up in these steps:\n",
    "\n",
    "- **[Load Reference Data](#load-reference-data)**\n",
    "- **[Transform Log-likelihood to Potential](#transform-log-likelihood-to-potential)**\n",
    "- **[RMSprop Adaption](#rmsprop-adaption)**\n",
    "- **[Integrator and Solver](#integrator-and-solver)**\n",
    "- **[Scheduler](#scheduler)**\n",
    "- **[Save Samples](#save-samples-in-numpy-arrays)**\n",
    "- **[Run Solver](#run-solver)**\n",
    "\n",
    "## Load Reference Data\n",
    "\n",
    "The reference data is passed to the solver via two components, the Data Loader\n",
    "and the Host Callback Wrapper.\n",
    "\n",
    "The Data Loader assembles the batches requested by the host callback wrappers.\n",
    "It loads the data from a source (HDF-File, numpy-array, tensorflow dataset)\n",
    "and selects the observations in each batch after a specific method\n",
    "(ordered access, shuffling, ...).\n",
    "\n",
    "The Host Callback Wrapper requests new batches from the Data Loader and loads\n",
    "them into jit-compiled programs via Jax's Host Callback module.\n",
    "To balance the memory usage and the delay due to loading the data, each device\n",
    "call returns multiple batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e37d57",
   "metadata": {
    "collapsed": false,
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "N = 4 \n",
    "samples = 1000 # Total samples\n",
    "\n",
    "key = random.PRNGKey(0)\n",
    "split1, split2, split3 = random.split(key, 3)\n",
    "\n",
    "# Correct solution\n",
    "sigma = 0.5\n",
    "w = random.uniform(split3, minval=-1, maxval=1, shape=(N, 1))\n",
    "\n",
    "# Data generation\n",
    "noise = sigma * random.normal(split2, shape=(samples, 1))\n",
    "x = random.uniform(split1, minval=-10, maxval=10, shape=(samples, N))\n",
    "x = jnp.stack([x[:, 0] + x[:, 1], x[:, 1], 0.1 * x[:, 2] - 0.5 * x[:, 3],\n",
    "               x[:, 3]]).transpose()\n",
    "y = jnp.matmul(x, w) + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae921357",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The NumpyDataLoader assembles batches randomly by drawing from the the complete\n",
    "dataset with and without replacement (shuffeling).\n",
    "It also provides the possibility to start the batching from a defined state, \n",
    "controlled via the seed.\n",
    "\n",
    "These settings can be passed differently for every chain and are thus not passed\n",
    "during the initialization.\n",
    "Instead, they have to be passed during the\n",
    "[initialization of the chains](#integrator-and-solver).\n",
    "\n",
    "In this example, the batches are shuffled, i.e. every sample is used at least\n",
    "once before an already drawn sample is used again and the chains start at a\n",
    "defined state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68386946",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The construction of the data loader can be different. For the numpy data\n",
    "# loader, the numpy arrays can be passed as keyword arguments and are later\n",
    "# returned as a dictionary with corresponding keys.\n",
    "data_loader = NumpyDataLoader(x=x, y=y)\n",
    "\n",
    "# The cache size corresponds to the number of batches per cache. The state\n",
    "# initialized via the init function is necessary to identify which data chain\n",
    "# request new batches of data.\n",
    "data_fn = data.random_reference_data(data_loader,\n",
    "                                     mb_size=N,\n",
    "                                     cached_batches_count=100)\n",
    "\n",
    "data_loader_kwargs = {\n",
    "    \"seed\": 0,\n",
    "    \"shuffle\": True,\n",
    "    \"in_epochs\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee36c51",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Transform Log-likelihood to Potential\n",
    "\n",
    "The model is connected to the solver via the (log-)prior and (log-)likelihood\n",
    "function. The model for our problem is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b22a0f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def model(sample, observations):\n",
    "    weights = sample[\"w\"]\n",
    "    predictors = observations[\"x\"]\n",
    "    return jnp.dot(predictors, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0663961",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**JaxSGMC** supports samples in the form of pytrees, so no flattering of e.g.\n",
    "Neural Net parameters is necessary. In our case we can separate the standard\n",
    "deviation, which is only part of the likelihood, from the weights by using a\n",
    "dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e030252",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def likelihood(sample, observations):\n",
    "    sigma = jnp.exp(sample[\"log_sigma\"])\n",
    "    y = observations[\"y\"]\n",
    "    y_pred = model(sample, observations)\n",
    "    return norm.logpdf(y - y_pred, scale=sigma)\n",
    "\n",
    "def prior(sample):\n",
    "    return 1 / jnp.exp(sample[\"log_sigma\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ecb1f2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The prior and likelihood are not passed to the solver directly, but \n",
    "first transformed into a (stochastic) potential.\n",
    "This allows us to formulate the model and so the likelihood with only a single \n",
    "observation in mind and let **JaxSGMC** take care of evaluating it for a batch\n",
    "of observations. As the model is not computationally demanding, we let \n",
    "**JaxSGMC** vectorize the evaluation of the likelihood:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e0d9e6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "potential_fn = potential.minibatch_potential(prior=prior,\n",
    "                                             likelihood=likelihood,\n",
    "                                             strategy=\"vmap\")                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27b9cd8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## RMSprop Adaption\n",
    "\n",
    "The adaption module simplifies the implementation of an adaption strategy\n",
    "by raveling / unraveling the latent variables pytree.\n",
    "\n",
    "The RMSprop adaption is characterized by two parameters, which can be set\n",
    "dynamically for each chain.\n",
    "As for the data loader arguments, non-default RMSprop parameters must be passed\n",
    "during the [initialization of the chains](#integrator-and-solver)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7907ed06",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rms_prop_adaption = adaption.rms_prop()\n",
    "\n",
    "adaption_kwargs = {\n",
    "    \"lmbd\": 1e-6,\n",
    "    \"alpha\": 0.99\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54693e9f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Integrator and Solver\n",
    "\n",
    "The integrator proposes new samples based on a specific process which are then\n",
    "processed by the solver.\n",
    "For example, the solver might reject a proposal by a Metropolis Hastings\n",
    "acceptance step (AMAGOLD, SGGMC) or swap it with another proposal by a parallel\n",
    "tempering chain swap (reSGLD).\n",
    "\n",
    "In this case, a Langevin Diffusion process proposes a new sample, which is\n",
    "accepted unconditionally by the solver.\n",
    "\n",
    "After this step we defined our process.\n",
    "Therefore, we can now initialize the starting states of each chain with the\n",
    "dynamic settings for the data loader and adaption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19208608",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "langevin_diffusion = integrator.langevin_diffusion(potential_fn=potential_fn,\n",
    "                                                   batch_fn=data_fn,\n",
    "                                                   adaption=rms_prop_adaption)\n",
    "\n",
    "# Returns a triplet of init_fn, update_fn and get_fn\n",
    "rms_prop_solver = solver.sgmc(langevin_diffusion)\n",
    "\n",
    "# Initialize the solver by providing initial values for the latent variables.\n",
    "# We provide extra arguments for the data loader and the adaption method.\n",
    "init_sample = {\"log_sigma\": jnp.array(0.0), \"w\": jnp.zeros(N)}\n",
    "init_state = rms_prop_solver[0](init_sample,\n",
    "                                adaption_kwargs=adaption_kwargs,\n",
    "                                batch_kwargs=data_loader_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ded445",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Scheduler\n",
    "\n",
    "Next, we set up a schedule which updates process parameters such as the\n",
    "temperature and the step size independently of the solver state.\n",
    "It is moreover necessary to determine which samples should be saved or discarded.\n",
    "\n",
    "SGLD only depends on the step size, which is chosen to follow a polynomial\n",
    "schedule.\n",
    "However, as only a few and independent samples should be saved, we also set up a\n",
    "burn in schedule, which rejects the first 2000 samples and a thinning schedule,\n",
    "which randomly selects 1000 samples not subject to burn in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2930535",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "step_size_schedule = scheduler.polynomial_step_size_first_last(first=0.05,\n",
    "                                                               last=0.001,\n",
    "                                                               gamma=0.33)\n",
    "burn_in_schedule = scheduler.initial_burn_in(2000)\n",
    "thinning_schedule = scheduler.random_thinning(step_size_schedule=step_size_schedule,\n",
    "                                              burn_in_schedule=burn_in_schedule,\n",
    "                                              selections=1000)\n",
    "\n",
    "# Bundles all specific schedules\n",
    "schedule = scheduler.init_scheduler(step_size=step_size_schedule,\n",
    "                                    burn_in=burn_in_schedule,\n",
    "                                    thinning=thinning_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5e6cf8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Save samples in numpy Arrays\n",
    "\n",
    "By default, **JaxSGMC** save accepted samples in the device memory.\n",
    "However, for some models the required memory rapidly exceeds the available \n",
    "memory. Therefore, **JaxSGMC** supports saving the samples on the host in a\n",
    "similar manner as it loads reference data from the host.\n",
    "\n",
    "Hence, also the saving step consists of setting up a Data Collector, which takes\n",
    "care of saving the data in different formats and a general Host Callback Wrapper\n",
    "which transfers the data out of jit-compiled computations.\n",
    "\n",
    "In this example, the data is simply passed to (real) numpy arrays in the host\n",
    "memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e63a27",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_collector = io.MemoryCollector()\n",
    "save_fn = io.save(data_collector=data_collector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bcb4fe",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Save samples in hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938e2d59",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "data_collector = io.MemoryCollector()\n",
    "save_fn = io.save(data_collector=data_collector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3cfa1d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Run Solver\n",
    "\n",
    "Finally, all parts of the solver are set up and can be combined to a runnable\n",
    "process.\n",
    "The mcmc function updates the scheduler and integrator in the correct order and\n",
    "passes the results to the saving module. \n",
    "\n",
    "The mcmc function can be called with multiple ``init_states`` as\n",
    "positional arguments to run multiple chains and returns a list of results, one\n",
    "for each chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7ff80f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mcmc = solver.mcmc(solver=rms_prop_solver,\n",
    "                   scheduler=schedule,\n",
    "                   saving=save_fn)\n",
    "\n",
    "# Take the result of the first chain\n",
    "results = mcmc(init_state, iterations=10000)[0]\n",
    "\n",
    "\n",
    "print(f\"Collected {results['sample_count']} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68822a2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ade973",
   "metadata": {
    "collapsed": false,
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Sigma\")\n",
    "\n",
    "plt.plot(onp.exp(results[\"samples\"][\"variables\"][\"log_sigma\"]), label=\"RMSprop\")\n",
    "\n",
    "w_rms = results[\"samples\"][\"variables\"][\"w\"]\n",
    "\n",
    "# w1 vs w2\n",
    "w1d = onp.linspace(0.00, 0.20, 100)\n",
    "w2d = onp.linspace(-0.70, -0.30, 100)\n",
    "W1d, W2d = onp.meshgrid(w1d, w2d)\n",
    "p12d = onp.vstack([W1d.ravel(), W2d.ravel()])\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"w_1 vs w_2 (rms)\")\n",
    "\n",
    "plt.xlim([0.07, 0.12])\n",
    "plt.ylim([-0.525, -0.450])\n",
    "plt.plot(w_rms[:, 0], w_rms[:, 1], 'o', alpha=0.5, markersize=0.5, zorder=-1)\n",
    "\n",
    "# w3 vs w4\n",
    "w3d = onp.linspace(-0.3, -0.05, 100)\n",
    "w4d = onp.linspace(-0.75, -0.575, 100)\n",
    "W3d, W4d = onp.meshgrid(w3d, w4d)\n",
    "p34d = onp.vstack([W3d.ravel(), W4d.ravel()])\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"w_3 vs w_4 (rms)\")\n",
    "plt.plot(w_rms[:, 2], w_rms[:, 3], 'o', alpha=0.5, markersize=0.5, zorder=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2adc5d",
   "metadata": {},
   "source": [
    "## Large Models: Save Data to HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81de2b2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T07:28:54.566317Z",
     "iopub.status.busy": "2023-06-12T07:28:54.565967Z",
     "iopub.status.idle": "2023-06-12T07:28:56.746130Z",
     "shell.execute_reply": "2023-06-12T07:28:56.745298Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 0/10000](0%) Collected 0 of 1000 samples...\n",
      "[Step 500/10000](5%) Collected 0 of 1000 samples...\n",
      "[Step 1000/10000](10%) Collected 0 of 1000 samples...\n",
      "[Step 1500/10000](15%) Collected 0 of 1000 samples...\n",
      "[Step 2000/10000](20%) Collected 1 of 1000 samples...\n",
      "[Step 2500/10000](25%) Collected 87 of 1000 samples...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 3000/10000](30%) Collected 168 of 1000 samples...\n",
      "[Step 3500/10000](35%) Collected 245 of 1000 samples...\n",
      "[Step 4000/10000](40%) Collected 315 of 1000 samples...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 4500/10000](45%) Collected 374 of 1000 samples...\n",
      "[Step 5000/10000](50%) Collected 437 of 1000 samples...\n",
      "[Step 5500/10000](55%) Collected 496 of 1000 samples...\n",
      "[Step 6000/10000](60%) Collected 551 of 1000 samples...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 6500/10000](65%) Collected 613 of 1000 samples...\n",
      "[Step 7000/10000](70%) Collected 682 of 1000 samples...\n",
      "[Step 7500/10000](75%) Collected 736 of 1000 samples...\n",
      "[Step 8000/10000](80%) Collected 787 of 1000 samples...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 8500/10000](85%) Collected 839 of 1000 samples...\n",
      "[Step 9000/10000](90%) Collected 898 of 1000 samples...\n",
      "[Step 9500/10000](95%) Collected 953 of 1000 samples...\n",
      "Collected 1000 samples\n"
     ]
    }
   ],
   "source": [
    "# Open a HDF5 file to store data in\n",
    "with h5py.File(\"sgld_rms.hdf5\", \"w\") as file:\n",
    "\n",
    "    data_collector = io.HDF5Collector(file)\n",
    "    save_fn = io.save(data_collector=data_collector)\n",
    "\n",
    "    mcmc = solver.mcmc(solver=rms_prop_solver,\n",
    "                   scheduler=schedule,\n",
    "                   saving=save_fn)\n",
    "\n",
    "    # The solver has to be reinitialized, as the data loader has to be reinitialized\n",
    "    init_state = rms_prop_solver[0](init_sample,\n",
    "                                    adaption_kwargs=adaption_kwargs,\n",
    "                                    batch_kwargs=data_loader_kwargs)\n",
    "    results = mcmc(init_state, iterations=10000)[0]\n",
    "\n",
    "print(f\"Collected {results['sample_count']} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d744a31d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T07:28:56.751028Z",
     "iopub.status.busy": "2023-06-12T07:28:56.750009Z",
     "iopub.status.idle": "2023-06-12T07:28:57.879015Z",
     "shell.execute_reply": "2023-06-12T07:28:57.878214Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 1000 samples with means:\n",
      "  w_0: new = 0.09378340095281601, old = 0.09378334879875183)\n",
      "  w_1: new = -0.4894007742404938, old = -0.4894009232521057)\n",
      "  w_2: new = -0.14092718064785004, old = -0.14092722535133362)\n",
      "  w_3: new = -0.6256959438323975, old = -0.6256959438323975)\n"
     ]
    }
   ],
   "source": [
    "# Sum up and count all values\n",
    "def map_fn(batch, mask, count):\n",
    "    return jnp.sum(batch[\"w\"].T * mask, axis=1), count + jnp.sum(mask)\n",
    "\n",
    "# Load only the samples from the file\n",
    "with h5py.File(\"sgld_rms.hdf5\", \"r\") as file:\n",
    "    postprocess_loader = HDF5Loader(file, subdir=\"/chain~0/variables\", sample=init_sample)\n",
    "\n",
    "    full_data_mapper, _ = data.full_data_mapper(postprocess_loader, 128, 128)\n",
    "    w_sums, count = full_data_mapper(map_fn, 0, masking=True)\n",
    "\n",
    "    # Sum up the sums from the individual batches\n",
    "    w_means = jnp.sum(w_sums, axis=0) / count\n",
    "\n",
    "print(f\"Collected {count} samples with means:\")\n",
    "for idx, (w, w_old) in enumerate(zip(w_means, onp.mean(w_rms, axis=0))):\n",
    "  print(f\"  w_{idx}: new = {w}, old = {w_old})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05be3171",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T07:28:57.883676Z",
     "iopub.status.busy": "2023-06-12T07:28:57.883065Z",
     "iopub.status.idle": "2023-06-12T07:28:57.887483Z",
     "shell.execute_reply": "2023-06-12T07:28:57.886653Z"
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.remove(\"sgld_rms.hdf5\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "examples///ipynb,examples///md:myst,docs//usage//ipynb",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
